{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30aa48d7",
   "metadata": {},
   "source": [
    "# CRUST-bench Multi-Stage Fine-Tuning Pipeline\n",
    "\n",
    "This notebook covers dataset loading, stage 1 fine-tuning on stubs, pseudo-labeling for full transpilation, stage 2 fine-tuning, and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a8bdd2",
   "metadata": {},
   "source": [
    "## 1. Setup Environment\n",
    "```bash\n",
    "# Create and activate conda environment\n",
    "conda env create -f environment.yml\n",
    "conda activate crustbench\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3b9b2f",
   "metadata": {},
   "source": [
    "## 2: Dataset Loading and Preprocessing\n",
    "Below we define `CRUSTLoader`, a helper class that:\n",
    "- **Locates** all project directories under `datasets/CBench`.\n",
    "- **Reads** `.c` and `.h` files, filters out tests/examples, and **removes comments**.\n",
    "- **Merges** header files into their corresponding C sources to create self-contained code snippets.\n",
    "- **Pairs** each cleaned C snippet with its Rust stub interface by matching filename stems.\n",
    "\n",
    "This prepares raw data for instruction-style fine-tuning in chat format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5167c109",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "class CRUSTLoader:\n",
    "    def __init__(self, cbench_dir: str, rbench_dir: str):\n",
    "        self.cbench = Path(cbench_dir)\n",
    "        self.rbench = Path(rbench_dir)\n",
    "        # only directories under CBench are projects\n",
    "        self.projects = [p.name for p in self.cbench.iterdir() if p.is_dir()]\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_comments(code: str) -> str:\n",
    "        # strip single-line comments\n",
    "        code = re.sub(r\"//.*?\\n\", \"\\n\", code)\n",
    "        # strip block comments\n",
    "        code = re.sub(r\"/\\*.*?\\*/\", \"\", code, flags=re.DOTALL)\n",
    "        # collapse multiple blank lines\n",
    "        return re.sub(r\"\\n+\", \"\\n\", code)\n",
    "\n",
    "    def get_c_files(self, project: str) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Load all .c and .h files (excluding tests/examples/bin) for one project,\n",
    "        return list of {'file_name': ..., 'content': ...}\n",
    "        \"\"\"\n",
    "        records = []\n",
    "        base = self.cbench / project\n",
    "        for f in base.rglob(\"*\"):\n",
    "            if not f.is_file(): \n",
    "                continue\n",
    "            if f.suffix not in {\".c\", \".h\"}:\n",
    "                continue\n",
    "            if any(x in f.parts for x in (\"test\", \"tests\", \"example\", \"examples\", \"bin\", \"unity\")):\n",
    "                continue\n",
    "            raw = f.read_text(errors=\"ignore\")\n",
    "            txt = self.remove_comments(raw)\n",
    "            records.append({\"file_name\": f.name, \"content\": txt})\n",
    "        # sort for deterministic output\n",
    "        return sorted(records, key=lambda d: d[\"file_name\"])\n",
    "\n",
    "    def process_c_and_h(self, c_records: List[Dict]) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Merge headers into their corresponding .c where both exist.\n",
    "        Returns a new list of records, with .h merged and renamed to .c.\n",
    "        \"\"\"\n",
    "        c_map = {r[\"file_name\"]: r[\"content\"] for r in c_records}\n",
    "        out = []\n",
    "        visited = set()\n",
    "\n",
    "        # iterate headers first, attach to .c\n",
    "        for rec in sorted(c_records, key=lambda d: d[\"file_name\"], reverse=True):\n",
    "            name = rec[\"file_name\"]\n",
    "            if name.endswith(\".h\"):\n",
    "                base = name[:-2] + \".c\"\n",
    "                if base in c_map:\n",
    "                    # merge header+source\n",
    "                    merged = (\n",
    "                        \"// from header\\n/*\\n\"\n",
    "                        + rec[\"content\"]\n",
    "                        + \"\\n*/\\n\"\n",
    "                        + c_map[base]\n",
    "                    )\n",
    "                    out.append({\"file_name\": base, \"content\": merged})\n",
    "                    visited.add(base)\n",
    "                else:\n",
    "                    out.append(rec)\n",
    "            else:\n",
    "                if name not in visited:\n",
    "                    out.append(rec)\n",
    "\n",
    "        # ensure sorted\n",
    "        return sorted(out, key=lambda d: d[\"file_name\"])\n",
    "\n",
    "    def load_rust_interfaces(self, project: str) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Load all stub interfaces (*.rs in src/interfaces) with their raw content.\n",
    "        \"\"\"\n",
    "        recs = []\n",
    "        intf_dir = self.rbench / project / \"src\" / \"interfaces\"\n",
    "        if intf_dir.exists():\n",
    "            for f in intf_dir.glob(\"*.rs\"):\n",
    "                recs.append({\"file_name\": f.name, \"content\": f.read_text()})\n",
    "        return sorted(recs, key=lambda d: d[\"file_name\"])\n",
    "\n",
    "    def load_rust_bins(self, project: str) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Load all test drivers (*.rs in src/bin) if you need them later.\n",
    "        \"\"\"\n",
    "        recs = []\n",
    "        bin_dir = self.rbench / project / \"src\" / \"bin\"\n",
    "        if bin_dir.exists():\n",
    "            for f in bin_dir.glob(\"*.rs\"):\n",
    "                recs.append({\"file_name\": f.name, \"content\": f.read_text()})\n",
    "        return sorted(recs, key=lambda d: d[\"file_name\"])\n",
    "\n",
    "    def get_interface_pairs(self) -> List[Tuple[Path, Path]]:\n",
    "        \"\"\"\n",
    "        For each project, returns list of (c_path, rust_interface_path)\n",
    "        by matching stems.\n",
    "        \"\"\"\n",
    "        pairs = []\n",
    "        for proj in self.projects:\n",
    "            c_recs = self.get_c_files(proj)\n",
    "            c_recs = self.process_c_and_h(c_recs)\n",
    "            rust_intfs = self.load_rust_interfaces(proj)\n",
    "\n",
    "            # build a map from stem to C record\n",
    "            cmap = {Path(r[\"file_name\"]).stem: r for r in c_recs}\n",
    "            for ri in rust_intfs:\n",
    "                stem = Path(ri[\"file_name\"]).stem\n",
    "                if stem in cmap:\n",
    "                    c_file = cmap[stem][\"content\"]\n",
    "                    r_file = ri[\"content\"]\n",
    "                    pairs.append((c_file, r_file))\n",
    "        return pairs\n",
    "\n",
    "    def export_jsonl(self, out_train: str, out_valid: str, split: float = 0.9):\n",
    "        \"\"\"\n",
    "        Write train/valid JSONL with instruction-style prompts & completions.\n",
    "        \"\"\"\n",
    "        exs = []\n",
    "        for ctext, rtext in self.get_interface_pairs():\n",
    "            exs.append({\"ctext\": ctext, \"rtext\": rtext})\n",
    "\n",
    "        cut = int(len(exs) * split)\n",
    "        for path, batch in [(out_train, exs[:cut]), (out_valid, exs[cut:])]:\n",
    "            p = Path(path)\n",
    "            p.parent.mkdir(parents=True, exist_ok=True)\n",
    "            with p.open(\"w\") as f:\n",
    "                for e in batch:\n",
    "                    f.write(json.dumps(e) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512b8400",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = CRUSTLoader(\"datasets/CBench\", \"datasets/RBench\")\n",
    "loader.export_jsonl(\"train.jsonl\", \"valid.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea417294",
   "metadata": {},
   "source": [
    "## 4. Convert to instruction-style (chat-style) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d9079b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def to_chat_example(line):\n",
    "    ex = json.loads(line)\n",
    "    # take your old prompt/completion\n",
    "    ctext, rtext = ex[\"ctext\"], ex[\"rtext\"]\n",
    "    return {\n",
    "      \"messages\": [\n",
    "        {\"role\":\"system\",\"content\":\"You are a Rust expert tasked with translating C to Rust.\"},\n",
    "        {\"role\":\"user\",\"content\": \"Translate the following C code into fully implemented, idiomatic, and compilable Rust.```c\" +\n",
    "                    ctext + \"```\"},\n",
    "        {\"role\":\"assistant\",\"content\": \"```rust\" + rtext + \"```\"}\n",
    "      ],\n",
    "    }\n",
    "\n",
    "def convert(in_path: Path, out_path: Path):\n",
    "    with in_path.open() as fin, out_path.open(\"w\") as fout:\n",
    "        for line in fin:\n",
    "            fout.write(json.dumps(to_chat_example(line)) + \"\\n\")\n",
    "\n",
    "# Convert both train & valid\n",
    "convert(Path(\"train.jsonl\"), Path(\"train_stage1.jsonl\"))\n",
    "convert(Path(\"valid.jsonl\"), Path(\"valid_stage1.jsonl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b98451",
   "metadata": {},
   "source": [
    "## 4.1 Stage 1 upload Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6d46ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train file ID: file-Uc7nuJ3vq2a175zy9rSGNc\n",
      "Valid file ID: file-QR2o1ETk6BFHM9GNERgZJi\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Upload dataset\n",
    "train_file = client.files.create(\n",
    "    file=open('train_stage1.jsonl', 'rb'),\n",
    "    purpose='fine-tune'\n",
    ")\n",
    "valid_file = client.files.create(\n",
    "    file=open('valid_stage1.jsonl', 'rb'),\n",
    "    purpose='fine-tune'\n",
    ")\n",
    "\n",
    "print(f\"Train file ID: {train_file.id}\")\n",
    "print(f\"Valid file ID: {valid_file.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d31693e",
   "metadata": {},
   "source": [
    "## 4.2 Stage 1 Fine-Tuning (Stubs)\n",
    "Upload files and start fine-tune on `gpt-3.5-turbo`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c239c85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage1 FT Job ID: ftjob-4LPBSZI2pisefYDjuonYaJSq\n"
     ]
    }
   ],
   "source": [
    "# Launch fine-tune\n",
    "job = client.fine_tuning.jobs.create(\n",
    "    training_file=train_file.id,\n",
    "    validation_file=valid_file.id,\n",
    "    model='gpt-4.1-nano-2025-04-14'\n",
    ")\n",
    "print(\"Stage1 FT Job ID:\", job.id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a0539e",
   "metadata": {},
   "source": [
    "## 4.3: Monitoring Training Metrics\n",
    "We poll the fine-tuning job's events to extract **`metrics`** events, which include:\n",
    "- Training and validation loss per step\n",
    "- Mean token-level accuracy metrics\n",
    "\n",
    "Printing these in real time helps you verify convergence and detect issues early."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3c909b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Monitor Fine-Tuning Job\n",
    "# Replace JOB_ID with your actual fine-tune job ID\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "def print_metrics(job_id):\n",
    "\n",
    "    # Poll until at least some metrics are available\n",
    "    all_metrics = []\n",
    "    while True:\n",
    "        evts = client.fine_tuning.jobs.list_events(\n",
    "            fine_tuning_job_id=job_id, limit=100\n",
    "        ).data\n",
    "        # extract only the metrics events\n",
    "        for e in evts:\n",
    "            print(f\"Event: {e.type} - {e.created_at} - {e.message}\")\n",
    "            if e.type == \"metrics\" and e.data not in all_metrics:\n",
    "                all_metrics.append(e.data)\n",
    "                print(f\"New metrics event: {e.data}\")\n",
    "                print(f\"Step {e.data['step']}: train_loss={e.data['train_loss']:.4f}, valid_loss={e.data.get('valid_loss', -1):.4f}\")\n",
    "        # exit once job is done\n",
    "        status = client.fine_tuning.jobs.retrieve(fine_tuning_job_id=job_id).status\n",
    "        if status in (\"succeeded\", \"failed\"):\n",
    "            break\n",
    "        time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ef56cbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event: message - 1750191642 - The job has successfully completed\n",
      "Event: message - 1750191635 - Usage policy evaluations completed, model is now enabled for sampling\n",
      "Event: moderation_checks - 1750191635 - Moderation checks for snapshot ft:gpt-4.1-nano-2025-04-14:personal::BjWp3qnB passed.\n",
      "Event: message - 1750190629 - Evaluating model against our usage policies\n",
      "Event: message - 1750190629 - New fine-tuned model created\n",
      "Event: message - 1750190629 - Checkpoint created at step 386\n",
      "Event: message - 1750190629 - Checkpoint created at step 193\n",
      "Event: metrics - 1750190581 - Step 579/579: training loss=0.20, validation loss=0.62, full validation loss=0.42\n",
      "New metrics event: {'step': 579, 'train_loss': 0.20390063524246216, 'valid_loss': 0.6245212878211069, 'total_steps': 579, 'full_valid_loss': 0.4175889157885576, 'train_mean_token_accuracy': 0.9356725215911865, 'valid_mean_token_accuracy': 0.8135593220338984, 'full_valid_mean_token_accuracy': 0.8911336873701223}\n",
      "Step 579: train_loss=0.2039, valid_loss=0.6245\n",
      "Event: metrics - 1750190576 - Step 578/579: training loss=0.02\n",
      "New metrics event: {'step': 578, 'train_loss': 0.020608356222510338, 'total_steps': 579, 'train_mean_token_accuracy': 0.988095223903656}\n",
      "Step 578: train_loss=0.0206, valid_loss=-1.0000\n",
      "Event: metrics - 1750190576 - Step 577/579: training loss=0.01\n",
      "New metrics event: {'step': 577, 'train_loss': 0.007985221222043037, 'total_steps': 579, 'train_mean_token_accuracy': 1.0}\n",
      "Step 577: train_loss=0.0080, valid_loss=-1.0000\n",
      "Event: metrics - 1750190576 - Step 576/579: training loss=0.03\n",
      "New metrics event: {'step': 576, 'train_loss': 0.025864219292998314, 'total_steps': 579, 'train_mean_token_accuracy': 0.9750000238418579}\n",
      "Step 576: train_loss=0.0259, valid_loss=-1.0000\n",
      "Event: metrics - 1750190576 - Step 575/579: training loss=0.25\n",
      "New metrics event: {'step': 575, 'train_loss': 0.2510708272457123, 'total_steps': 579, 'train_mean_token_accuracy': 0.9284741282463074}\n",
      "Step 575: train_loss=0.2511, valid_loss=-1.0000\n",
      "Event: metrics - 1750190576 - Step 574/579: training loss=0.08\n",
      "New metrics event: {'step': 574, 'train_loss': 0.08283120393753052, 'total_steps': 579, 'train_mean_token_accuracy': 0.9782270789146423}\n",
      "Step 574: train_loss=0.0828, valid_loss=-1.0000\n",
      "Event: metrics - 1750190576 - Step 573/579: training loss=0.35\n",
      "New metrics event: {'step': 573, 'train_loss': 0.35498735308647156, 'total_steps': 579, 'train_mean_token_accuracy': 0.8888888955116272}\n",
      "Step 573: train_loss=0.3550, valid_loss=-1.0000\n",
      "Event: metrics - 1750190571 - Step 572/579: training loss=0.72\n",
      "New metrics event: {'step': 572, 'train_loss': 0.7178425192832947, 'total_steps': 579, 'train_mean_token_accuracy': 0.818652868270874}\n",
      "Step 572: train_loss=0.7178, valid_loss=-1.0000\n",
      "Event: metrics - 1750190571 - Step 571/579: training loss=0.45\n",
      "New metrics event: {'step': 571, 'train_loss': 0.45071449875831604, 'total_steps': 579, 'train_mean_token_accuracy': 0.868852436542511}\n",
      "Step 571: train_loss=0.4507, valid_loss=-1.0000\n",
      "Event: metrics - 1750190569 - Step 570/579: training loss=0.08, validation loss=0.18\n",
      "New metrics event: {'step': 570, 'train_loss': 0.08198042958974838, 'valid_loss': 0.1834607200017051, 'total_steps': 579, 'train_mean_token_accuracy': 0.9868420958518982, 'valid_mean_token_accuracy': 0.946031746031746}\n",
      "Step 570: train_loss=0.0820, valid_loss=0.1835\n",
      "Event: metrics - 1750190565 - Step 569/579: training loss=0.35\n",
      "New metrics event: {'step': 569, 'train_loss': 0.34822121262550354, 'total_steps': 579, 'train_mean_token_accuracy': 0.9002848863601685}\n",
      "Step 569: train_loss=0.3482, valid_loss=-1.0000\n",
      "Event: metrics - 1750190565 - Step 568/579: training loss=0.11\n",
      "New metrics event: {'step': 568, 'train_loss': 0.1059894859790802, 'total_steps': 579, 'train_mean_token_accuracy': 0.9699699878692627}\n",
      "Step 568: train_loss=0.1060, valid_loss=-1.0000\n",
      "Event: metrics - 1750190565 - Step 567/579: training loss=0.10\n",
      "New metrics event: {'step': 567, 'train_loss': 0.10250275582075119, 'total_steps': 579, 'train_mean_token_accuracy': 0.9710144996643066}\n",
      "Step 567: train_loss=0.1025, valid_loss=-1.0000\n",
      "Event: metrics - 1750190565 - Step 566/579: training loss=0.15\n",
      "New metrics event: {'step': 566, 'train_loss': 0.14838962256908417, 'total_steps': 579, 'train_mean_token_accuracy': 0.9572815299034119}\n",
      "Step 566: train_loss=0.1484, valid_loss=-1.0000\n",
      "Event: metrics - 1750190565 - Step 565/579: training loss=0.20\n",
      "New metrics event: {'step': 565, 'train_loss': 0.2007572501897812, 'total_steps': 579, 'train_mean_token_accuracy': 0.9541984796524048}\n",
      "Step 565: train_loss=0.2008, valid_loss=-1.0000\n",
      "Event: metrics - 1750190565 - Step 564/579: training loss=0.22\n",
      "New metrics event: {'step': 564, 'train_loss': 0.21878083050251007, 'total_steps': 579, 'train_mean_token_accuracy': 0.9259259104728699}\n",
      "Step 564: train_loss=0.2188, valid_loss=-1.0000\n",
      "Event: metrics - 1750190565 - Step 563/579: training loss=0.10\n",
      "New metrics event: {'step': 563, 'train_loss': 0.0952901840209961, 'total_steps': 579, 'train_mean_token_accuracy': 0.9716088175773621}\n",
      "Step 563: train_loss=0.0953, valid_loss=-1.0000\n",
      "Event: metrics - 1750190561 - Step 562/579: training loss=0.00\n",
      "New metrics event: {'step': 562, 'train_loss': 0.0005735207232646644, 'total_steps': 579, 'train_mean_token_accuracy': 1.0}\n",
      "Step 562: train_loss=0.0006, valid_loss=-1.0000\n",
      "Event: metrics - 1750190561 - Step 561/579: training loss=0.06\n",
      "New metrics event: {'step': 561, 'train_loss': 0.056114982813596725, 'total_steps': 579, 'train_mean_token_accuracy': 0.9849849939346313}\n",
      "Step 561: train_loss=0.0561, valid_loss=-1.0000\n",
      "Event: metrics - 1750190559 - Step 560/579: training loss=0.04, validation loss=0.23\n",
      "New metrics event: {'step': 560, 'train_loss': 0.03900257870554924, 'valid_loss': 0.2294156167754816, 'total_steps': 579, 'train_mean_token_accuracy': 0.9882044792175293, 'valid_mean_token_accuracy': 0.9348268839103869}\n",
      "Step 560: train_loss=0.0390, valid_loss=0.2294\n",
      "Event: metrics - 1750190555 - Step 559/579: training loss=0.02\n",
      "New metrics event: {'step': 559, 'train_loss': 0.01549359131604433, 'total_steps': 579, 'train_mean_token_accuracy': 1.0}\n",
      "Step 559: train_loss=0.0155, valid_loss=-1.0000\n",
      "Event: metrics - 1750190555 - Step 558/579: training loss=0.50\n",
      "New metrics event: {'step': 558, 'train_loss': 0.4964315593242645, 'total_steps': 579, 'train_mean_token_accuracy': 0.850220263004303}\n",
      "Step 558: train_loss=0.4964, valid_loss=-1.0000\n",
      "Event: metrics - 1750190555 - Step 557/579: training loss=0.11\n",
      "New metrics event: {'step': 557, 'train_loss': 0.11116323620080948, 'total_steps': 579, 'train_mean_token_accuracy': 0.9711815714836121}\n",
      "Step 557: train_loss=0.1112, valid_loss=-1.0000\n",
      "Event: metrics - 1750190555 - Step 556/579: training loss=0.20\n",
      "New metrics event: {'step': 556, 'train_loss': 0.1970241367816925, 'total_steps': 579, 'train_mean_token_accuracy': 0.9283667802810669}\n",
      "Step 556: train_loss=0.1970, valid_loss=-1.0000\n",
      "Event: metrics - 1750190555 - Step 555/579: training loss=0.01\n",
      "New metrics event: {'step': 555, 'train_loss': 0.012425231747329235, 'total_steps': 579, 'train_mean_token_accuracy': 1.0}\n",
      "Step 555: train_loss=0.0124, valid_loss=-1.0000\n",
      "Event: metrics - 1750190555 - Step 554/579: training loss=0.11\n",
      "New metrics event: {'step': 554, 'train_loss': 0.10807741433382034, 'total_steps': 579, 'train_mean_token_accuracy': 0.9675675630569458}\n",
      "Step 554: train_loss=0.1081, valid_loss=-1.0000\n",
      "Event: metrics - 1750190555 - Step 553/579: training loss=0.17\n",
      "New metrics event: {'step': 553, 'train_loss': 0.1651492565870285, 'total_steps': 579, 'train_mean_token_accuracy': 0.9535518884658813}\n",
      "Step 553: train_loss=0.1651, valid_loss=-1.0000\n",
      "Event: metrics - 1750190551 - Step 552/579: training loss=0.18\n",
      "New metrics event: {'step': 552, 'train_loss': 0.1813189834356308, 'total_steps': 579, 'train_mean_token_accuracy': 0.9240506291389465}\n",
      "Step 552: train_loss=0.1813, valid_loss=-1.0000\n",
      "Event: metrics - 1750190550 - Step 551/579: training loss=0.11\n",
      "New metrics event: {'step': 551, 'train_loss': 0.10784995555877686, 'total_steps': 579, 'train_mean_token_accuracy': 0.9651162624359131}\n",
      "Step 551: train_loss=0.1078, valid_loss=-1.0000\n",
      "Event: metrics - 1750190550 - Step 550/579: training loss=0.13, validation loss=0.17\n",
      "New metrics event: {'step': 550, 'train_loss': 0.13052630424499512, 'valid_loss': 0.1728886554115697, 'total_steps': 579, 'train_mean_token_accuracy': 0.9624999761581421, 'valid_mean_token_accuracy': 0.9454887218045113}\n",
      "Step 550: train_loss=0.1305, valid_loss=0.1729\n",
      "Event: metrics - 1750190550 - Step 549/579: training loss=0.26\n",
      "New metrics event: {'step': 549, 'train_loss': 0.25753769278526306, 'total_steps': 579, 'train_mean_token_accuracy': 0.9347826242446899}\n",
      "Step 549: train_loss=0.2575, valid_loss=-1.0000\n",
      "Event: metrics - 1750190550 - Step 548/579: training loss=0.18\n",
      "New metrics event: {'step': 548, 'train_loss': 0.18227027356624603, 'total_steps': 579, 'train_mean_token_accuracy': 0.9614678621292114}\n",
      "Step 548: train_loss=0.1823, valid_loss=-1.0000\n",
      "Event: metrics - 1750190545 - Step 547/579: training loss=0.46\n",
      "New metrics event: {'step': 547, 'train_loss': 0.45622989535331726, 'total_steps': 579, 'train_mean_token_accuracy': 0.8765996098518372}\n",
      "Step 547: train_loss=0.4562, valid_loss=-1.0000\n",
      "Event: metrics - 1750190545 - Step 546/579: training loss=0.11\n",
      "New metrics event: {'step': 546, 'train_loss': 0.10938728600740433, 'total_steps': 579, 'train_mean_token_accuracy': 0.9774436354637146}\n",
      "Step 546: train_loss=0.1094, valid_loss=-1.0000\n",
      "Event: metrics - 1750190545 - Step 545/579: training loss=0.25\n",
      "New metrics event: {'step': 545, 'train_loss': 0.2469327449798584, 'total_steps': 579, 'train_mean_token_accuracy': 0.9453125}\n",
      "Step 545: train_loss=0.2469, valid_loss=-1.0000\n",
      "Event: metrics - 1750190545 - Step 544/579: training loss=0.13\n",
      "New metrics event: {'step': 544, 'train_loss': 0.13201861083507538, 'total_steps': 579, 'train_mean_token_accuracy': 0.9532467722892761}\n",
      "Step 544: train_loss=0.1320, valid_loss=-1.0000\n",
      "Event: metrics - 1750190545 - Step 543/579: training loss=0.27\n",
      "New metrics event: {'step': 543, 'train_loss': 0.2738357186317444, 'total_steps': 579, 'train_mean_token_accuracy': 0.9029126167297363}\n",
      "Step 543: train_loss=0.2738, valid_loss=-1.0000\n",
      "Event: metrics - 1750190545 - Step 542/579: training loss=0.16\n",
      "New metrics event: {'step': 542, 'train_loss': 0.15546418726444244, 'total_steps': 579, 'train_mean_token_accuracy': 0.9575328826904297}\n",
      "Step 542: train_loss=0.1555, valid_loss=-1.0000\n",
      "Event: metrics - 1750190545 - Step 541/579: training loss=0.09\n",
      "New metrics event: {'step': 541, 'train_loss': 0.0899873748421669, 'total_steps': 579, 'train_mean_token_accuracy': 0.9620689749717712}\n",
      "Step 541: train_loss=0.0900, valid_loss=-1.0000\n",
      "Event: metrics - 1750190544 - Step 540/579: training loss=0.13, validation loss=0.79\n",
      "New metrics event: {'step': 540, 'train_loss': 0.13495087623596191, 'valid_loss': 0.7947179026377377, 'total_steps': 579, 'train_mean_token_accuracy': 0.9642857313156128, 'valid_mean_token_accuracy': 0.8057828696126569}\n",
      "Step 540: train_loss=0.1350, valid_loss=0.7947\n",
      "Event: metrics - 1750190540 - Step 539/579: training loss=1.15\n",
      "New metrics event: {'step': 539, 'train_loss': 1.148382306098938, 'total_steps': 579, 'train_mean_token_accuracy': 0.8039215803146362}\n",
      "Step 539: train_loss=1.1484, valid_loss=-1.0000\n",
      "Event: metrics - 1750190540 - Step 538/579: training loss=0.16\n",
      "New metrics event: {'step': 538, 'train_loss': 0.16401326656341553, 'total_steps': 579, 'train_mean_token_accuracy': 0.9561688303947449}\n",
      "Step 538: train_loss=0.1640, valid_loss=-1.0000\n",
      "Event: metrics - 1750190540 - Step 537/579: training loss=0.07\n",
      "New metrics event: {'step': 537, 'train_loss': 0.0731993168592453, 'total_steps': 579, 'train_mean_token_accuracy': 0.9750000238418579}\n",
      "Step 537: train_loss=0.0732, valid_loss=-1.0000\n",
      "Event: metrics - 1750190537 - Step 536/579: training loss=0.27\n",
      "New metrics event: {'step': 536, 'train_loss': 0.271345317363739, 'total_steps': 579, 'train_mean_token_accuracy': 0.9107142686843872}\n",
      "Step 536: train_loss=0.2713, valid_loss=-1.0000\n",
      "Event: metrics - 1750190533 - Step 535/579: training loss=0.17\n",
      "New metrics event: {'step': 535, 'train_loss': 0.1671643704175949, 'total_steps': 579, 'train_mean_token_accuracy': 0.9200000166893005}\n",
      "Step 535: train_loss=0.1672, valid_loss=-1.0000\n",
      "Event: metrics - 1750190533 - Step 534/579: training loss=0.19\n",
      "New metrics event: {'step': 534, 'train_loss': 0.19328536093235016, 'total_steps': 579, 'train_mean_token_accuracy': 0.9345454573631287}\n",
      "Step 534: train_loss=0.1933, valid_loss=-1.0000\n",
      "Event: metrics - 1750190533 - Step 533/579: training loss=0.05\n",
      "New metrics event: {'step': 533, 'train_loss': 0.05384048447012901, 'total_steps': 579, 'train_mean_token_accuracy': 0.978723406791687}\n",
      "Step 533: train_loss=0.0538, valid_loss=-1.0000\n",
      "Event: metrics - 1750190533 - Step 532/579: training loss=0.22\n",
      "New metrics event: {'step': 532, 'train_loss': 0.22368589043617249, 'total_steps': 579, 'train_mean_token_accuracy': 0.95652174949646}\n",
      "Step 532: train_loss=0.2237, valid_loss=-1.0000\n",
      "Event: metrics - 1750190533 - Step 531/579: training loss=0.07\n",
      "New metrics event: {'step': 531, 'train_loss': 0.06637752056121826, 'total_steps': 579, 'train_mean_token_accuracy': 0.9840954542160034}\n",
      "Step 531: train_loss=0.0664, valid_loss=-1.0000\n",
      "Event: metrics - 1750190532 - Step 530/579: training loss=0.07, validation loss=0.23\n",
      "New metrics event: {'step': 530, 'train_loss': 0.07485076040029526, 'valid_loss': 0.23290396151335344, 'total_steps': 579, 'train_mean_token_accuracy': 0.9877049326896667, 'valid_mean_token_accuracy': 0.9565217391304348}\n",
      "Step 530: train_loss=0.0749, valid_loss=0.2329\n",
      "Event: metrics - 1750190528 - Step 529/579: training loss=0.09\n",
      "New metrics event: {'step': 529, 'train_loss': 0.09258224815130234, 'total_steps': 579, 'train_mean_token_accuracy': 0.971563994884491}\n",
      "Step 529: train_loss=0.0926, valid_loss=-1.0000\n",
      "Event: metrics - 1750190528 - Step 528/579: training loss=0.44\n",
      "New metrics event: {'step': 528, 'train_loss': 0.43556588888168335, 'total_steps': 579, 'train_mean_token_accuracy': 0.8774459362030029}\n",
      "Step 528: train_loss=0.4356, valid_loss=-1.0000\n",
      "Event: metrics - 1750190528 - Step 527/579: training loss=0.04\n",
      "New metrics event: {'step': 527, 'train_loss': 0.038558173924684525, 'total_steps': 579, 'train_mean_token_accuracy': 0.9926470518112183}\n",
      "Step 527: train_loss=0.0386, valid_loss=-1.0000\n",
      "Event: metrics - 1750190528 - Step 526/579: training loss=0.28\n",
      "New metrics event: {'step': 526, 'train_loss': 0.28484758734703064, 'total_steps': 579, 'train_mean_token_accuracy': 0.9182839393615723}\n",
      "Step 526: train_loss=0.2848, valid_loss=-1.0000\n",
      "Event: metrics - 1750190527 - Step 525/579: training loss=0.01\n",
      "New metrics event: {'step': 525, 'train_loss': 0.012458020821213722, 'total_steps': 579, 'train_mean_token_accuracy': 1.0}\n",
      "Step 525: train_loss=0.0125, valid_loss=-1.0000\n",
      "Event: metrics - 1750190523 - Step 524/579: training loss=0.05\n",
      "New metrics event: {'step': 524, 'train_loss': 0.04730679839849472, 'total_steps': 579, 'train_mean_token_accuracy': 0.9883268475532532}\n",
      "Step 524: train_loss=0.0473, valid_loss=-1.0000\n",
      "Event: metrics - 1750190523 - Step 523/579: training loss=0.91\n",
      "New metrics event: {'step': 523, 'train_loss': 0.9109574556350708, 'total_steps': 579, 'train_mean_token_accuracy': 0.7142857313156128}\n",
      "Step 523: train_loss=0.9110, valid_loss=-1.0000\n",
      "Event: metrics - 1750190523 - Step 522/579: training loss=0.03\n",
      "New metrics event: {'step': 522, 'train_loss': 0.02879882976412773, 'total_steps': 579, 'train_mean_token_accuracy': 1.0}\n",
      "Step 522: train_loss=0.0288, valid_loss=-1.0000\n",
      "Event: metrics - 1750190523 - Step 521/579: training loss=0.56\n",
      "New metrics event: {'step': 521, 'train_loss': 0.5580732822418213, 'total_steps': 579, 'train_mean_token_accuracy': 0.8247863054275513}\n",
      "Step 521: train_loss=0.5581, valid_loss=-1.0000\n",
      "Event: metrics - 1750190522 - Step 520/579: training loss=0.11, validation loss=0.53\n",
      "New metrics event: {'step': 520, 'train_loss': 0.10912638157606125, 'valid_loss': 0.5252835066422172, 'total_steps': 579, 'train_mean_token_accuracy': 0.9526315927505493, 'valid_mean_token_accuracy': 0.8260869565217391}\n",
      "Step 520: train_loss=0.1091, valid_loss=0.5253\n",
      "Event: metrics - 1750190518 - Step 519/579: training loss=0.06\n",
      "New metrics event: {'step': 519, 'train_loss': 0.0571107380092144, 'total_steps': 579, 'train_mean_token_accuracy': 0.9824561476707458}\n",
      "Step 519: train_loss=0.0571, valid_loss=-1.0000\n",
      "Event: metrics - 1750190518 - Step 518/579: training loss=0.96\n",
      "New metrics event: {'step': 518, 'train_loss': 0.9571160078048706, 'total_steps': 579, 'train_mean_token_accuracy': 0.6666666865348816}\n",
      "Step 518: train_loss=0.9571, valid_loss=-1.0000\n",
      "Event: metrics - 1750190518 - Step 517/579: training loss=0.14\n",
      "New metrics event: {'step': 517, 'train_loss': 0.13877537846565247, 'total_steps': 579, 'train_mean_token_accuracy': 0.9619883298873901}\n",
      "Step 517: train_loss=0.1388, valid_loss=-1.0000\n",
      "Event: metrics - 1750190518 - Step 516/579: training loss=0.04\n",
      "New metrics event: {'step': 516, 'train_loss': 0.03609812632203102, 'total_steps': 579, 'train_mean_token_accuracy': 0.9851484894752502}\n",
      "Step 516: train_loss=0.0361, valid_loss=-1.0000\n",
      "Event: metrics - 1750190518 - Step 515/579: training loss=0.24\n",
      "New metrics event: {'step': 515, 'train_loss': 0.24363137781620026, 'total_steps': 579, 'train_mean_token_accuracy': 0.942105233669281}\n",
      "Step 515: train_loss=0.2436, valid_loss=-1.0000\n",
      "Event: metrics - 1750190517 - Step 514/579: training loss=0.06\n",
      "New metrics event: {'step': 514, 'train_loss': 0.057152941823005676, 'total_steps': 579, 'train_mean_token_accuracy': 0.9856887459754944}\n",
      "Step 514: train_loss=0.0572, valid_loss=-1.0000\n",
      "Event: metrics - 1750190513 - Step 513/579: training loss=0.09\n",
      "New metrics event: {'step': 513, 'train_loss': 0.09340818971395493, 'total_steps': 579, 'train_mean_token_accuracy': 0.9655172228813171}\n",
      "Step 513: train_loss=0.0934, valid_loss=-1.0000\n",
      "Event: metrics - 1750190513 - Step 512/579: training loss=0.10\n",
      "New metrics event: {'step': 512, 'train_loss': 0.09817688912153244, 'total_steps': 579, 'train_mean_token_accuracy': 0.9629629850387573}\n",
      "Step 512: train_loss=0.0982, valid_loss=-1.0000\n",
      "Event: metrics - 1750190513 - Step 511/579: training loss=0.01\n",
      "New metrics event: {'step': 511, 'train_loss': 0.012029072269797325, 'total_steps': 579, 'train_mean_token_accuracy': 1.0}\n",
      "Step 511: train_loss=0.0120, valid_loss=-1.0000\n",
      "Event: metrics - 1750190512 - Step 510/579: training loss=0.22, validation loss=0.55\n",
      "New metrics event: {'step': 510, 'train_loss': 0.21592526137828827, 'valid_loss': 0.5500958355105653, 'total_steps': 579, 'train_mean_token_accuracy': 0.9432759881019592, 'valid_mean_token_accuracy': 0.8571428571428571}\n",
      "Step 510: train_loss=0.2159, valid_loss=0.5501\n",
      "Event: metrics - 1750190508 - Step 509/579: training loss=0.02\n",
      "New metrics event: {'step': 509, 'train_loss': 0.022351345047354698, 'total_steps': 579, 'train_mean_token_accuracy': 0.9830508232116699}\n",
      "Step 509: train_loss=0.0224, valid_loss=-1.0000\n",
      "Event: metrics - 1750190508 - Step 508/579: training loss=0.00\n",
      "New metrics event: {'step': 508, 'train_loss': 0.00017597313853912055, 'total_steps': 579, 'train_mean_token_accuracy': 1.0}\n",
      "Step 508: train_loss=0.0002, valid_loss=-1.0000\n",
      "Event: metrics - 1750190508 - Step 507/579: training loss=0.07\n",
      "New metrics event: {'step': 507, 'train_loss': 0.07164448499679565, 'total_steps': 579, 'train_mean_token_accuracy': 0.9776119589805603}\n",
      "Step 507: train_loss=0.0716, valid_loss=-1.0000\n",
      "Event: metrics - 1750190508 - Step 506/579: training loss=0.07\n",
      "New metrics event: {'step': 506, 'train_loss': 0.07260137796401978, 'total_steps': 579, 'train_mean_token_accuracy': 0.9810725450515747}\n",
      "Step 506: train_loss=0.0726, valid_loss=-1.0000\n",
      "Event: metrics - 1750190508 - Step 505/579: training loss=0.21\n",
      "New metrics event: {'step': 505, 'train_loss': 0.2112833857536316, 'total_steps': 579, 'train_mean_token_accuracy': 0.9200000166893005}\n",
      "Step 505: train_loss=0.2113, valid_loss=-1.0000\n",
      "Event: metrics - 1750190508 - Step 504/579: training loss=0.09\n",
      "New metrics event: {'step': 504, 'train_loss': 0.08561616390943527, 'total_steps': 579, 'train_mean_token_accuracy': 0.9642857313156128}\n",
      "Step 504: train_loss=0.0856, valid_loss=-1.0000\n",
      "Event: metrics - 1750190508 - Step 503/579: training loss=0.01\n",
      "New metrics event: {'step': 503, 'train_loss': 0.011269192211329937, 'total_steps': 579, 'train_mean_token_accuracy': 1.0}\n",
      "Step 503: train_loss=0.0113, valid_loss=-1.0000\n",
      "Event: metrics - 1750190507 - Step 502/579: training loss=0.37\n",
      "New metrics event: {'step': 502, 'train_loss': 0.37050947546958923, 'total_steps': 579, 'train_mean_token_accuracy': 0.9091967344284058}\n",
      "Step 502: train_loss=0.3705, valid_loss=-1.0000\n",
      "Event: metrics - 1750190501 - Step 501/579: training loss=0.14\n",
      "New metrics event: {'step': 501, 'train_loss': 0.14040623605251312, 'total_steps': 579, 'train_mean_token_accuracy': 0.955456554889679}\n",
      "Step 501: train_loss=0.1404, valid_loss=-1.0000\n",
      "Event: metrics - 1750190501 - Step 500/579: training loss=0.09, validation loss=0.54\n",
      "New metrics event: {'step': 500, 'train_loss': 0.08880215883255005, 'valid_loss': 0.5394610130735733, 'total_steps': 579, 'train_mean_token_accuracy': 0.9655172228813171, 'valid_mean_token_accuracy': 0.8583690987124464}\n",
      "Step 500: train_loss=0.0888, valid_loss=0.5395\n",
      "Event: metrics - 1750190501 - Step 499/579: training loss=0.09\n",
      "New metrics event: {'step': 499, 'train_loss': 0.08791394531726837, 'total_steps': 579, 'train_mean_token_accuracy': 0.9818181991577148}\n",
      "Step 499: train_loss=0.0879, valid_loss=-1.0000\n",
      "Event: metrics - 1750190501 - Step 498/579: training loss=0.27\n",
      "New metrics event: {'step': 498, 'train_loss': 0.2662520408630371, 'total_steps': 579, 'train_mean_token_accuracy': 0.9236573576927185}\n",
      "Step 498: train_loss=0.2663, valid_loss=-1.0000\n",
      "Event: metrics - 1750190501 - Step 497/579: training loss=0.25\n",
      "New metrics event: {'step': 497, 'train_loss': 0.24886730313301086, 'total_steps': 579, 'train_mean_token_accuracy': 0.9269005656242371}\n",
      "Step 497: train_loss=0.2489, valid_loss=-1.0000\n",
      "Event: metrics - 1750190496 - Step 496/579: training loss=0.18\n",
      "New metrics event: {'step': 496, 'train_loss': 0.1764547973871231, 'total_steps': 579, 'train_mean_token_accuracy': 0.9484536051750183}\n",
      "Step 496: train_loss=0.1765, valid_loss=-1.0000\n",
      "Event: metrics - 1750190496 - Step 495/579: training loss=0.17\n",
      "New metrics event: {'step': 495, 'train_loss': 0.17238281667232513, 'total_steps': 579, 'train_mean_token_accuracy': 0.9506173133850098}\n",
      "Step 495: train_loss=0.1724, valid_loss=-1.0000\n",
      "Event: metrics - 1750190496 - Step 494/579: training loss=0.29\n",
      "New metrics event: {'step': 494, 'train_loss': 0.28757134079933167, 'total_steps': 579, 'train_mean_token_accuracy': 0.8833333253860474}\n",
      "Step 494: train_loss=0.2876, valid_loss=-1.0000\n",
      "Event: metrics - 1750190496 - Step 493/579: training loss=0.24\n",
      "New metrics event: {'step': 493, 'train_loss': 0.24314725399017334, 'total_steps': 579, 'train_mean_token_accuracy': 0.9320388436317444}\n",
      "Step 493: train_loss=0.2431, valid_loss=-1.0000\n",
      "Event: metrics - 1750190496 - Step 492/579: training loss=0.02\n",
      "New metrics event: {'step': 492, 'train_loss': 0.01633393205702305, 'total_steps': 579, 'train_mean_token_accuracy': 0.9940476417541504}\n",
      "Step 492: train_loss=0.0163, valid_loss=-1.0000\n",
      "Event: metrics - 1750190495 - Step 491/579: training loss=0.08\n",
      "New metrics event: {'step': 491, 'train_loss': 0.08460057526826859, 'total_steps': 579, 'train_mean_token_accuracy': 0.9760000109672546}\n",
      "Step 491: train_loss=0.0846, valid_loss=-1.0000\n",
      "Event: metrics - 1750190490 - Step 490/579: training loss=0.26, validation loss=0.02\n",
      "New metrics event: {'step': 490, 'train_loss': 0.25958260893821716, 'valid_loss': 0.022671826680501304, 'total_steps': 579, 'train_mean_token_accuracy': 0.9215425252914429, 'valid_mean_token_accuracy': 1.0}\n",
      "Step 490: train_loss=0.2596, valid_loss=0.0227\n",
      "Event: metrics - 1750190490 - Step 489/579: training loss=0.77\n",
      "New metrics event: {'step': 489, 'train_loss': 0.7711812257766724, 'total_steps': 579, 'train_mean_token_accuracy': 0.8033472895622253}\n",
      "Step 489: train_loss=0.7712, valid_loss=-1.0000\n",
      "Event: metrics - 1750190490 - Step 488/579: training loss=0.22\n",
      "New metrics event: {'step': 488, 'train_loss': 0.2213771790266037, 'total_steps': 579, 'train_mean_token_accuracy': 0.9437652826309204}\n",
      "Step 488: train_loss=0.2214, valid_loss=-1.0000\n",
      "Event: metrics - 1750190486 - Step 487/579: training loss=0.34\n",
      "New metrics event: {'step': 487, 'train_loss': 0.3401000201702118, 'total_steps': 579, 'train_mean_token_accuracy': 0.89552241563797}\n",
      "Step 487: train_loss=0.3401, valid_loss=-1.0000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "job_id = \"ftjob-4LPBSZI2pisefYDjuonYaJSq\"\n",
    "\n",
    "print_metrics(job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645f0bb6",
   "metadata": {},
   "source": [
    "## 5.1 Stage 2: Pseudo-Labeling with GPT-4\n",
    "Here, we use the powerful `gpt-4` chat API to generate **full Rust implementations** from the C code plus the existing stub.  \n",
    "- For each entry, we prompt with both the original C snippet and the Rust stub.\n",
    "- The model returns a complete Rust translation, which we capture as a new training example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609ec6bc",
   "metadata": {},
   "source": [
    "## 5.2 Instruction-Style Fine-Tuning (Stage 2)\n",
    "We now fine-tune a second GPT-3.5 chat model on the fully-transpiled examples (`full_transpile.jsonl`). This encourages the model to learn true end-to-end C→Rust transpilation, not just stub filling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2fb91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 193 chat-style examples to full_transpile.jsonl\n"
     ]
    }
   ],
   "source": [
    "def transpile(ctext: str, stub: str) -> str:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a Rust expert.\"},\n",
    "        {\"role\": \"user\", \"content\": (\n",
    "            \"Translate this C code into fully implemented, idiomatic Rust. \"\n",
    "            \"Here’s the C code:\\n```c\\n\"\n",
    "            + ctext +\n",
    "            \"\\n```\\n\"\n",
    "            \"And here’s the existing Rust stub:\\n```rust\\n\"\n",
    "            + stub +\n",
    "            \"\\n```\"\n",
    "        )}\n",
    "    ]\n",
    "    resp = client.chat.completions.create(\n",
    "        model=\"gpt-4.1-nano\",\n",
    "        messages=messages,\n",
    "        max_tokens=2048,\n",
    "        temperature=0\n",
    "    )\n",
    "    return resp.choices[0].message.content\n",
    "\n",
    "input_path  = Path(\"train.jsonl\")\n",
    "output_path = Path(\"full_transpile.jsonl\")\n",
    "transpile_path = Path(\"train_transpile.jsonl\")\n",
    "entries = []\n",
    "\n",
    "new_data = []\n",
    "\n",
    "for line in input_path.read_text().splitlines():\n",
    "    ex    = json.loads(line)\n",
    "    ctext = ex[\"ctext\"]\n",
    "    stub  = ex[\"rtext\"]\n",
    "    full  = transpile(ctext, stub)\n",
    "    \n",
    "    new_data.append({\n",
    "        \"ctext\": ctext,\n",
    "        \"rtext\": stub,\n",
    "        \"full\": full\n",
    "    })\n",
    "\n",
    "    # now build a chat-style example\n",
    "    messages = [\n",
    "      {\"role\":\"system\",   \"content\":\"You are a Rust expert.\"},\n",
    "      {\"role\":\"user\",     \"content\":(\n",
    "         f\"Translate this C code into fully implemented Rust.\\n\"\n",
    "         f\"```c\\n{ctext}\\n```\\n\"\n",
    "      )},\n",
    "      {\"role\":\"assistant\",\"content\": full}\n",
    "    ]\n",
    "\n",
    "    entries.append({\"messages\": messages})\n",
    "    \n",
    "\n",
    "with transpile_path.open(\"w\") as f:\n",
    "    for ex in new_data:\n",
    "        f.write(json.dumps(ex) + \"\\n\")\n",
    "\n",
    "with output_path.open(\"w\") as f:\n",
    "    for ex in entries:\n",
    "        f.write(json.dumps(ex) + \"\\n\")\n",
    "\n",
    "print(f\"Wrote {len(entries)} chat-style examples to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a50bce3",
   "metadata": {},
   "source": [
    "## 5.3. Stage 2 Fine-Tune on Full Transpiled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8b02e66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Transpile Train file ID: file-EzgWV7tQ5gUEXFmpzmBEEb\n"
     ]
    }
   ],
   "source": [
    "# Upload full_transpile.jsonl\n",
    "train_transpile_file = client.files.create(\n",
    "    file=open('full_transpile.jsonl', 'rb'),\n",
    "    purpose='fine-tune'\n",
    ")\n",
    "\n",
    "print(f\"Full Transpile Train file ID: {train_transpile_file.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b41bc999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage2 FT Job ID: ftjob-sHK5yvlKmPHDQGZ5KD9fANb4\n"
     ]
    }
   ],
   "source": [
    "# Launch second-stage fine-tune\n",
    "job = client.fine_tuning.jobs.create(\n",
    "    training_file=train_transpile_file.id,\n",
    "    model='gpt-4.1-nano-2025-04-14'\n",
    ")\n",
    "print(\"Stage2 FT Job ID:\", job.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "10634c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event: message - 1750197201 - The job has successfully completed\n",
      "Event: message - 1750197195 - Usage policy evaluations completed, model is now enabled for sampling\n",
      "Event: moderation_checks - 1750197195 - Moderation checks for snapshot ft:gpt-4.1-nano-2025-04-14:personal::BjYGioVU passed.\n",
      "Event: message - 1750196189 - Evaluating model against our usage policies\n",
      "Event: message - 1750196189 - New fine-tuned model created\n",
      "Event: message - 1750196188 - Checkpoint created at step 386\n",
      "Event: message - 1750196188 - Checkpoint created at step 193\n",
      "Event: metrics - 1750196180 - Step 579/579: training loss=0.07\n",
      "New metrics event: {'step': 579, 'train_loss': 0.06870583444833755, 'total_steps': 579, 'train_mean_token_accuracy': 0.976097583770752}\n",
      "Step 579: train_loss=0.0687, valid_loss=-1.0000\n",
      "Event: metrics - 1750196180 - Step 578/579: training loss=0.23\n",
      "New metrics event: {'step': 578, 'train_loss': 0.23106878995895386, 'total_steps': 579, 'train_mean_token_accuracy': 0.9442622661590576}\n",
      "Step 578: train_loss=0.2311, valid_loss=-1.0000\n",
      "Event: metrics - 1750196180 - Step 577/579: training loss=0.06\n",
      "New metrics event: {'step': 577, 'train_loss': 0.05728188157081604, 'total_steps': 579, 'train_mean_token_accuracy': 0.9814634323120117}\n",
      "Step 577: train_loss=0.0573, valid_loss=-1.0000\n",
      "Event: metrics - 1750196178 - Step 576/579: training loss=0.04\n",
      "New metrics event: {'step': 576, 'train_loss': 0.03745457902550697, 'total_steps': 579, 'train_mean_token_accuracy': 0.9897561073303223}\n",
      "Step 576: train_loss=0.0375, valid_loss=-1.0000\n",
      "Event: metrics - 1750196178 - Step 575/579: training loss=0.08\n",
      "New metrics event: {'step': 575, 'train_loss': 0.08153993636369705, 'total_steps': 579, 'train_mean_token_accuracy': 0.9721577763557434}\n",
      "Step 575: train_loss=0.0815, valid_loss=-1.0000\n",
      "Event: metrics - 1750196176 - Step 574/579: training loss=0.10\n",
      "New metrics event: {'step': 574, 'train_loss': 0.0961550697684288, 'total_steps': 579, 'train_mean_token_accuracy': 0.9733333587646484}\n",
      "Step 574: train_loss=0.0962, valid_loss=-1.0000\n",
      "Event: metrics - 1750196176 - Step 573/579: training loss=0.10\n",
      "New metrics event: {'step': 573, 'train_loss': 0.09895262867212296, 'total_steps': 579, 'train_mean_token_accuracy': 0.9688995480537415}\n",
      "Step 573: train_loss=0.0990, valid_loss=-1.0000\n",
      "Event: metrics - 1750196176 - Step 572/579: training loss=0.08\n",
      "New metrics event: {'step': 572, 'train_loss': 0.08288007229566574, 'total_steps': 579, 'train_mean_token_accuracy': 0.9702439308166504}\n",
      "Step 572: train_loss=0.0829, valid_loss=-1.0000\n",
      "Event: metrics - 1750196174 - Step 571/579: training loss=0.10\n",
      "New metrics event: {'step': 571, 'train_loss': 0.10449278354644775, 'total_steps': 579, 'train_mean_token_accuracy': 0.9646697640419006}\n",
      "Step 571: train_loss=0.1045, valid_loss=-1.0000\n",
      "Event: metrics - 1750196174 - Step 570/579: training loss=0.15\n",
      "New metrics event: {'step': 570, 'train_loss': 0.15361842513084412, 'total_steps': 579, 'train_mean_token_accuracy': 0.9437751173973083}\n",
      "Step 570: train_loss=0.1536, valid_loss=-1.0000\n",
      "Event: metrics - 1750196174 - Step 569/579: training loss=0.12\n",
      "New metrics event: {'step': 569, 'train_loss': 0.11814144998788834, 'total_steps': 579, 'train_mean_token_accuracy': 0.9639024138450623}\n",
      "Step 569: train_loss=0.1181, valid_loss=-1.0000\n",
      "Event: metrics - 1750196172 - Step 568/579: training loss=0.08\n",
      "New metrics event: {'step': 568, 'train_loss': 0.08498110622167587, 'total_steps': 579, 'train_mean_token_accuracy': 0.9726829528808594}\n",
      "Step 568: train_loss=0.0850, valid_loss=-1.0000\n",
      "Event: metrics - 1750196172 - Step 567/579: training loss=0.09\n",
      "New metrics event: {'step': 567, 'train_loss': 0.08615978807210922, 'total_steps': 579, 'train_mean_token_accuracy': 0.9710467457771301}\n",
      "Step 567: train_loss=0.0862, valid_loss=-1.0000\n",
      "Event: metrics - 1750196170 - Step 566/579: training loss=0.09\n",
      "New metrics event: {'step': 566, 'train_loss': 0.0891520157456398, 'total_steps': 579, 'train_mean_token_accuracy': 0.971276581287384}\n",
      "Step 566: train_loss=0.0892, valid_loss=-1.0000\n",
      "Event: metrics - 1750196170 - Step 565/579: training loss=0.10\n",
      "New metrics event: {'step': 565, 'train_loss': 0.09813512861728668, 'total_steps': 579, 'train_mean_token_accuracy': 0.9673003554344177}\n",
      "Step 565: train_loss=0.0981, valid_loss=-1.0000\n",
      "Event: metrics - 1750196170 - Step 564/579: training loss=0.07\n",
      "New metrics event: {'step': 564, 'train_loss': 0.06673751026391983, 'total_steps': 579, 'train_mean_token_accuracy': 0.9780488014221191}\n",
      "Step 564: train_loss=0.0667, valid_loss=-1.0000\n",
      "Event: metrics - 1750196168 - Step 563/579: training loss=0.07\n",
      "New metrics event: {'step': 563, 'train_loss': 0.06577480584383011, 'total_steps': 579, 'train_mean_token_accuracy': 0.9804878234863281}\n",
      "Step 563: train_loss=0.0658, valid_loss=-1.0000\n",
      "Event: metrics - 1750196168 - Step 562/579: training loss=0.05\n",
      "New metrics event: {'step': 562, 'train_loss': 0.0538838766515255, 'total_steps': 579, 'train_mean_token_accuracy': 0.9839024543762207}\n",
      "Step 562: train_loss=0.0539, valid_loss=-1.0000\n",
      "Event: metrics - 1750196168 - Step 561/579: training loss=0.05\n",
      "New metrics event: {'step': 561, 'train_loss': 0.05451137572526932, 'total_steps': 579, 'train_mean_token_accuracy': 0.9824390411376953}\n",
      "Step 561: train_loss=0.0545, valid_loss=-1.0000\n",
      "Event: metrics - 1750196166 - Step 560/579: training loss=0.17\n",
      "New metrics event: {'step': 560, 'train_loss': 0.16725625097751617, 'total_steps': 579, 'train_mean_token_accuracy': 0.9546279311180115}\n",
      "Step 560: train_loss=0.1673, valid_loss=-1.0000\n",
      "Event: metrics - 1750196166 - Step 559/579: training loss=0.08\n",
      "New metrics event: {'step': 559, 'train_loss': 0.07746154814958572, 'total_steps': 579, 'train_mean_token_accuracy': 0.9751098155975342}\n",
      "Step 559: train_loss=0.0775, valid_loss=-1.0000\n",
      "Event: metrics - 1750196164 - Step 558/579: training loss=0.10\n",
      "New metrics event: {'step': 558, 'train_loss': 0.09509497880935669, 'total_steps': 579, 'train_mean_token_accuracy': 0.9682926535606384}\n",
      "Step 558: train_loss=0.0951, valid_loss=-1.0000\n",
      "Event: metrics - 1750196164 - Step 557/579: training loss=0.08\n",
      "New metrics event: {'step': 557, 'train_loss': 0.07894664257764816, 'total_steps': 579, 'train_mean_token_accuracy': 0.969613254070282}\n",
      "Step 557: train_loss=0.0789, valid_loss=-1.0000\n",
      "Event: metrics - 1750196164 - Step 556/579: training loss=0.06\n",
      "New metrics event: {'step': 556, 'train_loss': 0.06313558667898178, 'total_steps': 579, 'train_mean_token_accuracy': 0.9807427525520325}\n",
      "Step 556: train_loss=0.0631, valid_loss=-1.0000\n",
      "Event: metrics - 1750196162 - Step 555/579: training loss=0.06\n",
      "New metrics event: {'step': 555, 'train_loss': 0.05975937098264694, 'total_steps': 579, 'train_mean_token_accuracy': 0.9824390411376953}\n",
      "Step 555: train_loss=0.0598, valid_loss=-1.0000\n",
      "Event: metrics - 1750196162 - Step 554/579: training loss=0.08\n",
      "New metrics event: {'step': 554, 'train_loss': 0.07626159489154816, 'total_steps': 579, 'train_mean_token_accuracy': 0.9756097793579102}\n",
      "Step 554: train_loss=0.0763, valid_loss=-1.0000\n",
      "Event: metrics - 1750196162 - Step 553/579: training loss=0.18\n",
      "New metrics event: {'step': 553, 'train_loss': 0.1846802681684494, 'total_steps': 579, 'train_mean_token_accuracy': 0.9312169551849365}\n",
      "Step 553: train_loss=0.1847, valid_loss=-1.0000\n",
      "Event: metrics - 1750196160 - Step 552/579: training loss=0.09\n",
      "New metrics event: {'step': 552, 'train_loss': 0.0904320478439331, 'total_steps': 579, 'train_mean_token_accuracy': 0.9692206978797913}\n",
      "Step 552: train_loss=0.0904, valid_loss=-1.0000\n",
      "Event: metrics - 1750196160 - Step 551/579: training loss=0.11\n",
      "New metrics event: {'step': 551, 'train_loss': 0.11111710220575333, 'total_steps': 579, 'train_mean_token_accuracy': 0.961759090423584}\n",
      "Step 551: train_loss=0.1111, valid_loss=-1.0000\n",
      "Event: metrics - 1750196160 - Step 550/579: training loss=0.07\n",
      "New metrics event: {'step': 550, 'train_loss': 0.07068440318107605, 'total_steps': 579, 'train_mean_token_accuracy': 0.9780701994895935}\n",
      "Step 550: train_loss=0.0707, valid_loss=-1.0000\n",
      "Event: metrics - 1750196158 - Step 549/579: training loss=0.13\n",
      "New metrics event: {'step': 549, 'train_loss': 0.12732182443141937, 'total_steps': 579, 'train_mean_token_accuracy': 0.9565456509590149}\n",
      "Step 549: train_loss=0.1273, valid_loss=-1.0000\n",
      "Event: metrics - 1750196158 - Step 548/579: training loss=0.28\n",
      "New metrics event: {'step': 548, 'train_loss': 0.27687427401542664, 'total_steps': 579, 'train_mean_token_accuracy': 0.9040735960006714}\n",
      "Step 548: train_loss=0.2769, valid_loss=-1.0000\n",
      "Event: metrics - 1750196156 - Step 547/579: training loss=0.13\n",
      "New metrics event: {'step': 547, 'train_loss': 0.13242767751216888, 'total_steps': 579, 'train_mean_token_accuracy': 0.9604877829551697}\n",
      "Step 547: train_loss=0.1324, valid_loss=-1.0000\n",
      "Event: metrics - 1750196156 - Step 546/579: training loss=0.08\n",
      "New metrics event: {'step': 546, 'train_loss': 0.08022022992372513, 'total_steps': 579, 'train_mean_token_accuracy': 0.9738805890083313}\n",
      "Step 546: train_loss=0.0802, valid_loss=-1.0000\n",
      "Event: metrics - 1750196156 - Step 545/579: training loss=0.14\n",
      "New metrics event: {'step': 545, 'train_loss': 0.14380000531673431, 'total_steps': 579, 'train_mean_token_accuracy': 0.9585365653038025}\n",
      "Step 545: train_loss=0.1438, valid_loss=-1.0000\n",
      "Event: metrics - 1750196154 - Step 544/579: training loss=0.10\n",
      "New metrics event: {'step': 544, 'train_loss': 0.09919528663158417, 'total_steps': 579, 'train_mean_token_accuracy': 0.9693989157676697}\n",
      "Step 544: train_loss=0.0992, valid_loss=-1.0000\n",
      "Event: metrics - 1750196154 - Step 543/579: training loss=0.10\n",
      "New metrics event: {'step': 543, 'train_loss': 0.10047612339258194, 'total_steps': 579, 'train_mean_token_accuracy': 0.9759679436683655}\n",
      "Step 543: train_loss=0.1005, valid_loss=-1.0000\n",
      "Event: metrics - 1750196152 - Step 542/579: training loss=0.35\n",
      "New metrics event: {'step': 542, 'train_loss': 0.35306796431541443, 'total_steps': 579, 'train_mean_token_accuracy': 0.9086021780967712}\n",
      "Step 542: train_loss=0.3531, valid_loss=-1.0000\n",
      "Event: metrics - 1750196152 - Step 541/579: training loss=0.13\n",
      "New metrics event: {'step': 541, 'train_loss': 0.1306091696023941, 'total_steps': 579, 'train_mean_token_accuracy': 0.9595121741294861}\n",
      "Step 541: train_loss=0.1306, valid_loss=-1.0000\n",
      "Event: metrics - 1750196152 - Step 540/579: training loss=0.07\n",
      "New metrics event: {'step': 540, 'train_loss': 0.07448071241378784, 'total_steps': 579, 'train_mean_token_accuracy': 0.9765853881835938}\n",
      "Step 540: train_loss=0.0745, valid_loss=-1.0000\n",
      "Event: metrics - 1750196150 - Step 539/579: training loss=0.19\n",
      "New metrics event: {'step': 539, 'train_loss': 0.18947945535182953, 'total_steps': 579, 'train_mean_token_accuracy': 0.9376218318939209}\n",
      "Step 539: train_loss=0.1895, valid_loss=-1.0000\n",
      "Event: metrics - 1750196150 - Step 538/579: training loss=0.07\n",
      "New metrics event: {'step': 538, 'train_loss': 0.07195927947759628, 'total_steps': 579, 'train_mean_token_accuracy': 0.9768151044845581}\n",
      "Step 538: train_loss=0.0720, valid_loss=-1.0000\n",
      "Event: metrics - 1750196150 - Step 537/579: training loss=0.08\n",
      "New metrics event: {'step': 537, 'train_loss': 0.08242146670818329, 'total_steps': 579, 'train_mean_token_accuracy': 0.9723820686340332}\n",
      "Step 537: train_loss=0.0824, valid_loss=-1.0000\n",
      "Event: metrics - 1750196148 - Step 536/579: training loss=0.07\n",
      "New metrics event: {'step': 536, 'train_loss': 0.07015793025493622, 'total_steps': 579, 'train_mean_token_accuracy': 0.9783449172973633}\n",
      "Step 536: train_loss=0.0702, valid_loss=-1.0000\n",
      "Event: metrics - 1750196148 - Step 535/579: training loss=0.15\n",
      "New metrics event: {'step': 535, 'train_loss': 0.15216727554798126, 'total_steps': 579, 'train_mean_token_accuracy': 0.9510582089424133}\n",
      "Step 535: train_loss=0.1522, valid_loss=-1.0000\n",
      "Event: metrics - 1750196146 - Step 534/579: training loss=0.17\n",
      "New metrics event: {'step': 534, 'train_loss': 0.17048339545726776, 'total_steps': 579, 'train_mean_token_accuracy': 0.9526829123497009}\n",
      "Step 534: train_loss=0.1705, valid_loss=-1.0000\n",
      "Event: metrics - 1750196146 - Step 533/579: training loss=0.04\n",
      "New metrics event: {'step': 533, 'train_loss': 0.036155302077531815, 'total_steps': 579, 'train_mean_token_accuracy': 0.9892683029174805}\n",
      "Step 533: train_loss=0.0362, valid_loss=-1.0000\n",
      "Event: metrics - 1750196146 - Step 532/579: training loss=0.10\n",
      "New metrics event: {'step': 532, 'train_loss': 0.09942656755447388, 'total_steps': 579, 'train_mean_token_accuracy': 0.9653658270835876}\n",
      "Step 532: train_loss=0.0994, valid_loss=-1.0000\n",
      "Event: metrics - 1750196144 - Step 531/579: training loss=0.47\n",
      "New metrics event: {'step': 531, 'train_loss': 0.4663102626800537, 'total_steps': 579, 'train_mean_token_accuracy': 0.88162761926651}\n",
      "Step 531: train_loss=0.4663, valid_loss=-1.0000\n",
      "Event: metrics - 1750196144 - Step 530/579: training loss=0.12\n",
      "New metrics event: {'step': 530, 'train_loss': 0.11977639049291611, 'total_steps': 579, 'train_mean_token_accuracy': 0.9604441523551941}\n",
      "Step 530: train_loss=0.1198, valid_loss=-1.0000\n",
      "Event: metrics - 1750196142 - Step 529/579: training loss=0.07\n",
      "New metrics event: {'step': 529, 'train_loss': 0.0709109827876091, 'total_steps': 579, 'train_mean_token_accuracy': 0.9780488014221191}\n",
      "Step 529: train_loss=0.0709, valid_loss=-1.0000\n",
      "Event: metrics - 1750196142 - Step 528/579: training loss=0.03\n",
      "New metrics event: {'step': 528, 'train_loss': 0.03069203719496727, 'total_steps': 579, 'train_mean_token_accuracy': 0.9907317161560059}\n",
      "Step 528: train_loss=0.0307, valid_loss=-1.0000\n",
      "Event: metrics - 1750196142 - Step 527/579: training loss=0.13\n",
      "New metrics event: {'step': 527, 'train_loss': 0.12742632627487183, 'total_steps': 579, 'train_mean_token_accuracy': 0.9560975432395935}\n",
      "Step 527: train_loss=0.1274, valid_loss=-1.0000\n",
      "Event: metrics - 1750196140 - Step 526/579: training loss=0.11\n",
      "New metrics event: {'step': 526, 'train_loss': 0.11346442252397537, 'total_steps': 579, 'train_mean_token_accuracy': 0.9604877829551697}\n",
      "Step 526: train_loss=0.1135, valid_loss=-1.0000\n",
      "Event: metrics - 1750196140 - Step 525/579: training loss=0.15\n",
      "New metrics event: {'step': 525, 'train_loss': 0.1546093225479126, 'total_steps': 579, 'train_mean_token_accuracy': 0.9414814710617065}\n",
      "Step 525: train_loss=0.1546, valid_loss=-1.0000\n",
      "Event: metrics - 1750196139 - Step 524/579: training loss=0.05\n",
      "New metrics event: {'step': 524, 'train_loss': 0.053522150963544846, 'total_steps': 579, 'train_mean_token_accuracy': 0.9862637519836426}\n",
      "Step 524: train_loss=0.0535, valid_loss=-1.0000\n",
      "Event: metrics - 1750196137 - Step 523/579: training loss=0.12\n",
      "New metrics event: {'step': 523, 'train_loss': 0.12077164649963379, 'total_steps': 579, 'train_mean_token_accuracy': 0.9720044732093811}\n",
      "Step 523: train_loss=0.1208, valid_loss=-1.0000\n",
      "Event: metrics - 1750196137 - Step 522/579: training loss=0.33\n",
      "New metrics event: {'step': 522, 'train_loss': 0.33405330777168274, 'total_steps': 579, 'train_mean_token_accuracy': 0.9044368863105774}\n",
      "Step 522: train_loss=0.3341, valid_loss=-1.0000\n",
      "Event: metrics - 1750196137 - Step 521/579: training loss=0.06\n",
      "New metrics event: {'step': 521, 'train_loss': 0.06445535272359848, 'total_steps': 579, 'train_mean_token_accuracy': 0.9804444313049316}\n",
      "Step 521: train_loss=0.0645, valid_loss=-1.0000\n",
      "Event: metrics - 1750196135 - Step 520/579: training loss=0.10\n",
      "New metrics event: {'step': 520, 'train_loss': 0.09790053218603134, 'total_steps': 579, 'train_mean_token_accuracy': 0.9696969985961914}\n",
      "Step 520: train_loss=0.0979, valid_loss=-1.0000\n",
      "Event: metrics - 1750196135 - Step 519/579: training loss=0.07\n",
      "New metrics event: {'step': 519, 'train_loss': 0.0673103779554367, 'total_steps': 579, 'train_mean_token_accuracy': 0.9767080545425415}\n",
      "Step 519: train_loss=0.0673, valid_loss=-1.0000\n",
      "Event: metrics - 1750196133 - Step 518/579: training loss=0.08\n",
      "New metrics event: {'step': 518, 'train_loss': 0.07665510475635529, 'total_steps': 579, 'train_mean_token_accuracy': 0.9768240451812744}\n",
      "Step 518: train_loss=0.0767, valid_loss=-1.0000\n",
      "Event: metrics - 1750196133 - Step 517/579: training loss=0.05\n",
      "New metrics event: {'step': 517, 'train_loss': 0.05289985612034798, 'total_steps': 579, 'train_mean_token_accuracy': 0.9848780632019043}\n",
      "Step 517: train_loss=0.0529, valid_loss=-1.0000\n",
      "Event: metrics - 1750196133 - Step 516/579: training loss=0.10\n",
      "New metrics event: {'step': 516, 'train_loss': 0.09878265857696533, 'total_steps': 579, 'train_mean_token_accuracy': 0.9721854329109192}\n",
      "Step 516: train_loss=0.0988, valid_loss=-1.0000\n",
      "Event: metrics - 1750196131 - Step 515/579: training loss=0.20\n",
      "New metrics event: {'step': 515, 'train_loss': 0.20366080105304718, 'total_steps': 579, 'train_mean_token_accuracy': 0.9458536505699158}\n",
      "Step 515: train_loss=0.2037, valid_loss=-1.0000\n",
      "Event: metrics - 1750196131 - Step 514/579: training loss=0.12\n",
      "New metrics event: {'step': 514, 'train_loss': 0.12064473330974579, 'total_steps': 579, 'train_mean_token_accuracy': 0.9605361223220825}\n",
      "Step 514: train_loss=0.1206, valid_loss=-1.0000\n",
      "Event: metrics - 1750196131 - Step 513/579: training loss=0.17\n",
      "New metrics event: {'step': 513, 'train_loss': 0.17474670708179474, 'total_steps': 579, 'train_mean_token_accuracy': 0.9553734064102173}\n",
      "Step 513: train_loss=0.1747, valid_loss=-1.0000\n",
      "Event: metrics - 1750196129 - Step 512/579: training loss=0.07\n",
      "New metrics event: {'step': 512, 'train_loss': 0.06853942573070526, 'total_steps': 579, 'train_mean_token_accuracy': 0.9807909727096558}\n",
      "Step 512: train_loss=0.0685, valid_loss=-1.0000\n",
      "Event: metrics - 1750196129 - Step 511/579: training loss=0.12\n",
      "New metrics event: {'step': 511, 'train_loss': 0.12416211515665054, 'total_steps': 579, 'train_mean_token_accuracy': 0.9573459625244141}\n",
      "Step 511: train_loss=0.1242, valid_loss=-1.0000\n",
      "Event: metrics - 1750196129 - Step 510/579: training loss=0.13\n",
      "New metrics event: {'step': 510, 'train_loss': 0.1336415857076645, 'total_steps': 579, 'train_mean_token_accuracy': 0.9614325165748596}\n",
      "Step 510: train_loss=0.1336, valid_loss=-1.0000\n",
      "Event: metrics - 1750196127 - Step 509/579: training loss=0.20\n",
      "New metrics event: {'step': 509, 'train_loss': 0.19752264022827148, 'total_steps': 579, 'train_mean_token_accuracy': 0.9427710771560669}\n",
      "Step 509: train_loss=0.1975, valid_loss=-1.0000\n",
      "Event: metrics - 1750196127 - Step 508/579: training loss=0.12\n",
      "New metrics event: {'step': 508, 'train_loss': 0.12281746417284012, 'total_steps': 579, 'train_mean_token_accuracy': 0.9609793424606323}\n",
      "Step 508: train_loss=0.1228, valid_loss=-1.0000\n",
      "Event: metrics - 1750196127 - Step 507/579: training loss=0.09\n",
      "New metrics event: {'step': 507, 'train_loss': 0.08553015440702438, 'total_steps': 579, 'train_mean_token_accuracy': 0.9728752374649048}\n",
      "Step 507: train_loss=0.0855, valid_loss=-1.0000\n",
      "Event: metrics - 1750196125 - Step 506/579: training loss=0.13\n",
      "New metrics event: {'step': 506, 'train_loss': 0.13269132375717163, 'total_steps': 579, 'train_mean_token_accuracy': 0.9607843160629272}\n",
      "Step 506: train_loss=0.1327, valid_loss=-1.0000\n",
      "Event: metrics - 1750196125 - Step 505/579: training loss=0.10\n",
      "New metrics event: {'step': 505, 'train_loss': 0.09863095730543137, 'total_steps': 579, 'train_mean_token_accuracy': 0.9644339084625244}\n",
      "Step 505: train_loss=0.0986, valid_loss=-1.0000\n",
      "Event: metrics - 1750196125 - Step 504/579: training loss=0.11\n",
      "New metrics event: {'step': 504, 'train_loss': 0.1119200810790062, 'total_steps': 579, 'train_mean_token_accuracy': 0.9670165181159973}\n",
      "Step 504: train_loss=0.1119, valid_loss=-1.0000\n",
      "Event: metrics - 1750196123 - Step 503/579: training loss=0.08\n",
      "New metrics event: {'step': 503, 'train_loss': 0.07854554802179337, 'total_steps': 579, 'train_mean_token_accuracy': 0.973120927810669}\n",
      "Step 503: train_loss=0.0785, valid_loss=-1.0000\n",
      "Event: metrics - 1750196123 - Step 502/579: training loss=0.10\n",
      "New metrics event: {'step': 502, 'train_loss': 0.10099916905164719, 'total_steps': 579, 'train_mean_token_accuracy': 0.969072163105011}\n",
      "Step 502: train_loss=0.1010, valid_loss=-1.0000\n",
      "Event: metrics - 1750196121 - Step 501/579: training loss=0.08\n",
      "New metrics event: {'step': 501, 'train_loss': 0.08015179634094238, 'total_steps': 579, 'train_mean_token_accuracy': 0.9702439308166504}\n",
      "Step 501: train_loss=0.0802, valid_loss=-1.0000\n",
      "Event: metrics - 1750196121 - Step 500/579: training loss=0.17\n",
      "New metrics event: {'step': 500, 'train_loss': 0.17173577845096588, 'total_steps': 579, 'train_mean_token_accuracy': 0.9465240836143494}\n",
      "Step 500: train_loss=0.1717, valid_loss=-1.0000\n",
      "Event: metrics - 1750196121 - Step 499/579: training loss=0.15\n",
      "New metrics event: {'step': 499, 'train_loss': 0.1472930759191513, 'total_steps': 579, 'train_mean_token_accuracy': 0.9575070738792419}\n",
      "Step 499: train_loss=0.1473, valid_loss=-1.0000\n",
      "Event: metrics - 1750196119 - Step 498/579: training loss=0.04\n",
      "New metrics event: {'step': 498, 'train_loss': 0.04251997917890549, 'total_steps': 579, 'train_mean_token_accuracy': 0.9848780632019043}\n",
      "Step 498: train_loss=0.0425, valid_loss=-1.0000\n",
      "Event: metrics - 1750196119 - Step 497/579: training loss=0.12\n",
      "New metrics event: {'step': 497, 'train_loss': 0.11791060864925385, 'total_steps': 579, 'train_mean_token_accuracy': 0.9607577919960022}\n",
      "Step 497: train_loss=0.1179, valid_loss=-1.0000\n",
      "Event: metrics - 1750196119 - Step 496/579: training loss=0.22\n",
      "New metrics event: {'step': 496, 'train_loss': 0.21506279706954956, 'total_steps': 579, 'train_mean_token_accuracy': 0.9439024329185486}\n",
      "Step 496: train_loss=0.2151, valid_loss=-1.0000\n",
      "Event: metrics - 1750196117 - Step 495/579: training loss=0.08\n",
      "New metrics event: {'step': 495, 'train_loss': 0.07858255505561829, 'total_steps': 579, 'train_mean_token_accuracy': 0.9780219793319702}\n",
      "Step 495: train_loss=0.0786, valid_loss=-1.0000\n",
      "Event: metrics - 1750196117 - Step 494/579: training loss=0.03\n",
      "New metrics event: {'step': 494, 'train_loss': 0.028391120955348015, 'total_steps': 579, 'train_mean_token_accuracy': 0.9912195205688477}\n",
      "Step 494: train_loss=0.0284, valid_loss=-1.0000\n",
      "Event: metrics - 1750196117 - Step 493/579: training loss=0.13\n",
      "New metrics event: {'step': 493, 'train_loss': 0.1304480880498886, 'total_steps': 579, 'train_mean_token_accuracy': 0.9585163593292236}\n",
      "Step 493: train_loss=0.1304, valid_loss=-1.0000\n",
      "Event: metrics - 1750196115 - Step 492/579: training loss=0.10\n",
      "New metrics event: {'step': 492, 'train_loss': 0.09561596810817719, 'total_steps': 579, 'train_mean_token_accuracy': 0.9815303683280945}\n",
      "Step 492: train_loss=0.0956, valid_loss=-1.0000\n",
      "Event: metrics - 1750196115 - Step 491/579: training loss=0.17\n",
      "New metrics event: {'step': 491, 'train_loss': 0.1663169413805008, 'total_steps': 579, 'train_mean_token_accuracy': 0.9503816962242126}\n",
      "Step 491: train_loss=0.1663, valid_loss=-1.0000\n",
      "Event: metrics - 1750196113 - Step 490/579: training loss=0.32\n",
      "New metrics event: {'step': 490, 'train_loss': 0.31671053171157837, 'total_steps': 579, 'train_mean_token_accuracy': 0.9140495657920837}\n",
      "Step 490: train_loss=0.3167, valid_loss=-1.0000\n",
      "Event: metrics - 1750196113 - Step 489/579: training loss=0.16\n",
      "New metrics event: {'step': 489, 'train_loss': 0.15842978656291962, 'total_steps': 579, 'train_mean_token_accuracy': 0.9526938199996948}\n",
      "Step 489: train_loss=0.1584, valid_loss=-1.0000\n",
      "Event: metrics - 1750196113 - Step 488/579: training loss=0.20\n",
      "New metrics event: {'step': 488, 'train_loss': 0.19936490058898926, 'total_steps': 579, 'train_mean_token_accuracy': 0.9385365843772888}\n",
      "Step 488: train_loss=0.1994, valid_loss=-1.0000\n",
      "Event: metrics - 1750196111 - Step 487/579: training loss=0.14\n",
      "New metrics event: {'step': 487, 'train_loss': 0.14212681353092194, 'total_steps': 579, 'train_mean_token_accuracy': 0.9578670263290405}\n",
      "Step 487: train_loss=0.1421, valid_loss=-1.0000\n"
     ]
    }
   ],
   "source": [
    "job_id = job.id\n",
    "print_metrics(job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6279451a",
   "metadata": {},
   "source": [
    "## 6: Qualitative Evaluation\n",
    "Finally, we evaluate a handful of examples for:\n",
    "- **Quality**: computing a token-level **BLEU** score against the reference Rust implementation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f147852f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'bleu': 0.4502649507952619}, {'bleu': 0.21063448590878106}, {'bleu': 0.2392737051184368}, {'bleu': 0.2760314019175371}, {'bleu': 0.2577859944295302}]\n"
     ]
    }
   ],
   "source": [
    "import subprocess, tempfile\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "FT_MODEL_STAGE2 = 'ft:gpt-4.1-nano-2025-04-14:personal::BjYGioVU'  # replace with actual ID\n",
    "\n",
    "def bleu(ref: str, pred: str) -> float:\n",
    "    return sentence_bleu([ref.split()], pred.split(), weights=(0.25,)*4)\n",
    "\n",
    "# Evaluate first 5 samples\n",
    "samples = [json.loads(l) for l in open('full_transpile.jsonl')][:5]\n",
    "results = []\n",
    "for s in samples:\n",
    "    resp = client.chat.completions.create(\n",
    "        model=FT_MODEL_STAGE2,\n",
    "        messages=s['messages'][:2],\n",
    "        max_tokens=1024,\n",
    "        temperature=0\n",
    "    )\n",
    "    gen = resp.choices[0].message.content.strip()\n",
    "    results.append({\n",
    "        'bleu': bleu(s['messages'][2]['content'], gen)\n",
    "    })\n",
    "\n",
    "print(results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crustbench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
